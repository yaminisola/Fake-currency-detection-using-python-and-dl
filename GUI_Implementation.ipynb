{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b468f760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.8224, Train Accuracy: 34.64%\n",
      "Validation Loss: 1.0783, Validation Accuracy: 72.47%\n",
      "\n",
      "Epoch 2/10, Loss: 0.7762, Train Accuracy: 81.70%\n",
      "Validation Loss: 0.3924, Validation Accuracy: 92.70%\n",
      "\n",
      "Epoch 3/10, Loss: 0.2617, Train Accuracy: 93.46%\n",
      "Validation Loss: 0.1548, Validation Accuracy: 94.94%\n",
      "\n",
      "Epoch 4/10, Loss: 0.0818, Train Accuracy: 98.04%\n",
      "Validation Loss: 0.1177, Validation Accuracy: 94.94%\n",
      "\n",
      "Epoch 5/10, Loss: 0.0625, Train Accuracy: 98.04%\n",
      "Validation Loss: 0.0752, Validation Accuracy: 96.63%\n",
      "\n",
      "Epoch 6/10, Loss: 0.0079, Train Accuracy: 100.00%\n",
      "Validation Loss: 0.2962, Validation Accuracy: 95.51%\n",
      "\n",
      "Epoch 7/10, Loss: 0.0889, Train Accuracy: 97.39%\n",
      "Validation Loss: 0.0927, Validation Accuracy: 97.19%\n",
      "\n",
      "Epoch 8/10, Loss: 0.0981, Train Accuracy: 96.08%\n",
      "Validation Loss: 0.0489, Validation Accuracy: 98.31%\n",
      "\n",
      "Epoch 9/10, Loss: 0.0198, Train Accuracy: 98.69%\n",
      "Validation Loss: 0.0911, Validation Accuracy: 97.75%\n",
      "\n",
      "Epoch 10/10, Loss: 0.0813, Train Accuracy: 98.04%\n",
      "Validation Loss: 0.0695, Validation Accuracy: 97.19%\n",
      "\n",
      "Model training completed and saved.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "# Paths\n",
    "train_path = r\"C:\\Users\\yamin\\python programs\\My_Project\\Dataset\\Train\"\n",
    "valid_path = r\"C:\\Users\\yamin\\python programs\\My_Project\\Dataset\\Test\"\n",
    "model_save_path = \"alexnet_currency_model.pth\"\n",
    "\n",
    "# Parameters\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "learning_rate = 0.0001\n",
    "\n",
    "# Data Preprocessing and Augmentation\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((227, 227)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.Resize((227, 227)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = datasets.ImageFolder(train_path, transform=train_transforms)\n",
    "valid_dataset = datasets.ImageFolder(valid_path, transform=valid_transforms)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load Pretrained AlexNet Model\n",
    "alexnet = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Modify the classifier for the custom dataset\n",
    "num_classes = len(train_dataset.classes)\n",
    "alexnet.classifier[6] = nn.Linear(alexnet.classifier[6].in_features, num_classes)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "alexnet = alexnet.to(device)\n",
    "\n",
    "# Define Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(alexnet.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training Loop\n",
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, num_epochs):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss, correct, total = 0.0, 0, 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        train_accuracy = 100 * correct / total\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss, val_correct, val_total = 0.0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in valid_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "        print(f\"Validation Loss: {val_loss/len(valid_loader):.4f}, Validation Accuracy: {val_accuracy:.2f}%\\n\")\n",
    "\n",
    "# Train and Save Model\n",
    "train_model(alexnet, train_loader, valid_loader, criterion, optimizer, num_epochs)\n",
    "torch.save(alexnet.state_dict(), model_save_path)\n",
    "print(\"Model training completed and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e53cbf78-7a6d-4c79-b91d-80b387d58d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in c:\\users\\yamin\\appdata\\roaming\\python\\python312\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\yamin\\appdata\\roaming\\python\\python312\\site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\yamin\\appdata\\roaming\\python\\python312\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yamin\\appdata\\roaming\\python\\python312\\site-packages (from torch) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\yamin\\appdata\\roaming\\python\\python312\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\yamin\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (1.26.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10f29aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yamin\\AppData\\Local\\Temp\\ipykernel_6932\\2429377666.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  alexnet.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading model: Error(s) in loading state_dict for AlexNet:\n",
      "\tsize mismatch for classifier.6.weight: copying a param with shape torch.Size([7, 4096]) from checkpoint, the shape in current model is torch.Size([2, 4096]).\n",
      "\tsize mismatch for classifier.6.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "Ensure the model architecture is the same as the saved model.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from tkinter import Tk, Label, Button, filedialog\n",
    "from PIL import Image, ImageTk  # Use ImageTk for Tkinter compatibility\n",
    "\n",
    "# Define Paths for Model\n",
    "model_path = \"alexnet_currency_model.pth\"  # Path to your saved model\n",
    "\n",
    "# Load Pretrained AlexNet Model with specified weights\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model architecture with the pretrained weights\n",
    "alexnet = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Modify the final classifier layer for custom classes (Real or Fake)\n",
    "num_classes = 2  # \"Real\" or \"Fake\"\n",
    "alexnet.classifier[6] = nn.Linear(alexnet.classifier[6].in_features, num_classes)\n",
    "\n",
    "# Move model to the correct device (GPU or CPU)\n",
    "alexnet = alexnet.to(device)\n",
    "\n",
    "# Try to load the model state dict from the saved file\n",
    "try:\n",
    "    alexnet.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    alexnet.eval()\n",
    "    print(\"Model loaded successfully!\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"Ensure the model architecture is the same as the saved model.\")\n",
    "\n",
    "# Image Preprocessing\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((227, 227)),  # Resize to AlexNet input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# GUI Application\n",
    "class CurrencyNoteClassifier:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Currency Note Classifier\")\n",
    "        self.root.geometry(\"500x400\")\n",
    "        \n",
    "        self.label = Label(root, text=\"Upload a Currency Note Image\", font=(\"Arial\", 14))\n",
    "        self.label.pack(pady=20)\n",
    "        \n",
    "        self.upload_button = Button(root, text=\"Upload Image\", command=self.upload_image, font=(\"Arial\", 12))\n",
    "        self.upload_button.pack(pady=10)\n",
    "        \n",
    "        self.result_label = Label(root, text=\"\", font=(\"Arial\", 16), fg=\"blue\")\n",
    "        self.result_label.pack(pady=20)\n",
    "        \n",
    "        self.image_label = Label(root)\n",
    "        self.image_label.pack()\n",
    "\n",
    "    def upload_image(self):\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"Image Files\", \"*.jpg;*.jpeg;*.png\")])\n",
    "        if file_path:\n",
    "            # Use PIL to open the image and convert it to a Tkinter-compatible format\n",
    "            img = Image.open(file_path)\n",
    "            img.thumbnail((250, 250))  # Resize for display\n",
    "\n",
    "            # Convert the image to a format Tkinter understands (PhotoImage)\n",
    "            img_tk = ImageTk.PhotoImage(img)\n",
    "            \n",
    "            # Display the image in the GUI\n",
    "            self.image_label.image = img_tk\n",
    "            self.image_label.configure(image=self.image_label.image)\n",
    "            \n",
    "            # Preprocess the image and predict\n",
    "            result = self.predict_currency(img)\n",
    "            self.result_label.configure(text=f\"Prediction: {result}\")\n",
    "\n",
    "    def predict_currency(self, image):\n",
    "        # Preprocess the image\n",
    "        image = preprocess(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Predict using the model\n",
    "        with torch.no_grad():\n",
    "            outputs = alexnet(image)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Define class labels\n",
    "        classes = [\"Real\", \"Fake\"]\n",
    "        return classes[predicted.item()]\n",
    "\n",
    "# Initialize and run GUI\n",
    "root = Tk()\n",
    "app = CurrencyNoteClassifier(root)\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115c667e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yamin\\AppData\\Local\\Temp\\ipykernel_6932\\3342861601.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  alexnet.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading model: Error(s) in loading state_dict for AlexNet:\n",
      "\tsize mismatch for classifier.6.weight: copying a param with shape torch.Size([7, 4096]) from checkpoint, the shape in current model is torch.Size([2, 4096]).\n",
      "\tsize mismatch for classifier.6.bias: copying a param with shape torch.Size([7]) from checkpoint, the shape in current model is torch.Size([2]).\n",
      "Ensure the model architecture is the same as the saved model.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "from tkinter import Tk, Label, Button, filedialog\n",
    "from PIL import Image, ImageTk  # Use ImageTk for Tkinter compatibility\n",
    "\n",
    "# Define Paths for Model\n",
    "model_path = \"alexnet_currency_model.pth\"  # Path to your saved model\n",
    "\n",
    "# Load Pretrained AlexNet Model with specified weights\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the model architecture with the pretrained weights\n",
    "alexnet = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Modify the final classifier layer for custom classes (Real or Fake)\n",
    "num_classes = 2  # \"Real\" or \"Fake\"\n",
    "alexnet.classifier[6] = nn.Linear(alexnet.classifier[6].in_features, num_classes)\n",
    "\n",
    "# Move model to the correct device (GPU or CPU)\n",
    "alexnet = alexnet.to(device)\n",
    "\n",
    "# Try to load the model state dict from the saved file\n",
    "try:\n",
    "    alexnet.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    alexnet.eval()\n",
    "    print(\"Model loaded successfully!\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"Ensure the model architecture is the same as the saved model.\")\n",
    "\n",
    "# Image Preprocessing\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((227, 227)),  # Resize to AlexNet input size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# GUI Application\n",
    "class CurrencyNoteClassifier:\n",
    "    def __init__(self, root):\n",
    "        self.root = root\n",
    "        self.root.title(\"Currency Note Classifier\")\n",
    "        self.root.geometry(\"600x500\")  # Increased window size to fit more content\n",
    "        \n",
    "        self.label = Label(root, text=\"Upload a Currency Note Image\", font=(\"Arial\", 14))\n",
    "        self.label.pack(pady=20)\n",
    "        \n",
    "        self.upload_button = Button(root, text=\"Upload Image\", command=self.upload_image, font=(\"Arial\", 12))\n",
    "        self.upload_button.pack(pady=10)\n",
    "        \n",
    "        self.result_label = Label(root, text=\"\", font=(\"Arial\", 16), fg=\"blue\")\n",
    "        self.result_label.pack(pady=20)\n",
    "        \n",
    "        self.image_label = Label(root)\n",
    "        self.image_label.pack(pady=10)\n",
    "\n",
    "        self.grayscale_label = Label(root)\n",
    "        self.grayscale_label.pack(pady=10)\n",
    "\n",
    "    def upload_image(self):\n",
    "        file_path = filedialog.askopenfilename(filetypes=[(\"Image Files\", \"*.jpg;*.jpeg;*.png\")])\n",
    "        if file_path:\n",
    "            # Use PIL to open the image\n",
    "            img = Image.open(file_path)\n",
    "            img.thumbnail((250, 250))  # Resize for display\n",
    "\n",
    "            # Convert the image to a format Tkinter understands (PhotoImage)\n",
    "            img_tk = ImageTk.PhotoImage(img)\n",
    "            \n",
    "            # Display the original image in the GUI\n",
    "            self.image_label.image = img_tk\n",
    "            self.image_label.configure(image=self.image_label.image)\n",
    "\n",
    "            # Convert the image to grayscale\n",
    "            grayscale_img = img.convert('L')\n",
    "            grayscale_img.thumbnail((250, 250))  # Resize grayscale image for display\n",
    "\n",
    "            # Convert grayscale image to a format Tkinter understands\n",
    "            grayscale_img_tk = ImageTk.PhotoImage(grayscale_img)\n",
    "            \n",
    "            # Display the grayscale image in the GUI\n",
    "            self.grayscale_label.image = grayscale_img_tk\n",
    "            self.grayscale_label.configure(image=self.grayscale_label.image)\n",
    "\n",
    "            # Preprocess the original image and predict\n",
    "            result = self.predict_currency(img)\n",
    "            self.result_label.configure(text=f\"Prediction: {result}\")\n",
    "\n",
    "    def predict_currency(self, image):\n",
    "        # Preprocess the image for model input\n",
    "        image = preprocess(image).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Predict using the model\n",
    "        with torch.no_grad():\n",
    "            outputs = alexnet(image)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        # Define class labels\n",
    "        classes = [\"Real\", \"Fake\"]\n",
    "        return classes[predicted.item()]\n",
    "\n",
    "# Initialize and run GUI\n",
    "root = Tk()\n",
    "app = CurrencyNoteClassifier(root)\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd939a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchvision in c:\\users\\yamin\\appdata\\roaming\\python\\python312\\site-packages (0.20.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\yamin\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (1.26.2)\n",
      "Requirement already satisfied: torch==2.5.1 in c:\\users\\yamin\\appdata\\roaming\\python\\python312\\site-packages (from torchvision) (2.5.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\lib\\site-packages (from torch==2.5.1->torchvision) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\yamin\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.5.1->torchvision) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\yamin\\appdata\\roaming\\python\\python312\\site-packages (from torch==2.5.1->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch==2.5.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->torch==2.5.1->torchvision) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3773b741-2c85-492e-9eba-572f862ca1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777a455d-3a55-4ad7-88cd-2919a85bcbad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
